{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from math import ceil, floor\n",
    "from pprint import pprint\n",
    "from typing import List\n",
    "\n",
    "os.environ[\"DSP_CACHEBOOL\"] = \"TRUE\"\n",
    "os.environ[\"DSP_CACHEDIR\"] = \"./cache/library\"\n",
    "os.environ[\"DSP_NOTEBOOK_CACHEDIR\"] = \"./cache/notebook\"\n",
    "os.environ[\"LITELLM_MODE\"] = \"PRODUCTION\"\n",
    "\n",
    "import dsp\n",
    "import dspy\n",
    "import emoji\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import phoenix\n",
    "import pydantic\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch, LabeledFewShot\n",
    "from dspy.teleprompt.signature_opt_typed import optimize_signature\n",
    "from openinference.instrumentation.dspy import DSPyInstrumentor\n",
    "from opentelemetry import trace as trace_api\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import \\\n",
    "    OTLPSpanExporter\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "from library.types import *\n",
    "from library.utils import *\n",
    "\n",
    "phoenix.launch_app(host=\"localhost\", port=6006)\n",
    "tracer_provider = trace_sdk.TracerProvider()\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter(endpoint=\"http://localhost:6006/v1/traces\")))\n",
    "trace_api.set_tracer_provider(tracer_provider)\n",
    "DSPyInstrumentor().instrument()\n",
    "\n",
    "evaluate = Evaluate(devset=None, metric=None, num_threads=os.cpu_count() // 2, display_progress=True, display_table=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check and play with STOP sequences\n",
    "params = { \"max_tokens\": 1024, \"temperature\": 0.7 }\n",
    "\n",
    "gpt35 = dspy.ChatBackend(model=\"openai/gpt-3.5-turbo-instruct\", api_key=os.environ[\"OPENAI_API_KEY\"], params=params, attempts=3, system_prompt=SYSTEM_PROMPT)\n",
    "gpt4o = dspy.ChatBackend(model=\"openai/gpt-4o\", api_key=os.environ[\"OPENAI_API_KEY\"], params=params, attempts=3, system_prompt=SYSTEM_PROMPT)\n",
    "gqmix = dspy.ChatBackend(model=\"groq/mixtral-8x7b-32768\", api_key=os.environ[\"GROQ_API_KEY\"], params=params, attempts=3, system_prompt=SYSTEM_PROMPT)\n",
    "gqll3 = dspy.ChatBackend(model=\"groq/llama-3.2-11b-text-preview\", api_key=os.environ[\"GROQ_API_KEY\"], params=params, attempts=3, system_prompt=SYSTEM_PROMPT)\n",
    "asmix = dspy.ChatBackend(model=\"anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1\", api_key=os.environ[\"ANYSCALE_API_KEY\"], params=params, attempts=3, system_prompt=SYSTEM_PROMPT)\n",
    "asll3 = dspy.ChatBackend(model=\"anyscale/meta-llama/Meta-Llama-3-8B-Instruct\", api_key=os.environ[\"ANYSCALE_API_KEY\"], params=params, attempts=3, system_prompt=SYSTEM_PROMPT)\n",
    "fwl31 = dspy.ChatBackend(model=\"fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct\", api_key=os.environ[\"FIREWORKS_API_KEY\"], params=params, attempts=3, system_prompt=SYSTEM_PROMPT)\n",
    "\n",
    "dspy.configure(backend=gqll3, trace=[], cache=True) # trace=[] needed to run assertions and suggestions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: The current sample has a majority of english feedbacks,\n",
    "#Â this is ok for now but enhance in future iterations\n",
    "with open(\"artifacts/feedbacks/labeled.json\", \"r\") as file:\n",
    "    feedbacks = json.load(file)\n",
    "\n",
    "feedbacks = pd.DataFrame(feedbacks)\n",
    "display(feedbacks.head())\n",
    "print(f\"{ceil(feedbacks['content'].apply(len).mean())} average feedback length ~ {ceil(feedbacks['content'].apply(tokenizer).apply(len).mean())} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IssueGenerator(dspy.Module):\n",
    "    class Input(pydantic.BaseModel):\n",
    "        context: str\n",
    "        feedback: str\n",
    "\n",
    "    class Output(pydantic.BaseModel):\n",
    "        class Issue(pydantic.BaseModel):\n",
    "            title: str\n",
    "            description: str\n",
    "            steps: List[str]\n",
    "\n",
    "        issues: List[Issue]\n",
    "\n",
    "    class GenerateIssues(dspy.Signature):\n",
    "        \"\"\"\n",
    "List valid issues, that a customer has with a product (context is provided), from the customer's feedback.\n",
    "- Issues that the customer did not explicitly state are invalid issues.\n",
    "- If the customer is uncertain of an issue it is an invalid issue.\n",
    "- Issues without steps to reproduce them are still valid issues.\n",
    "- Suggestions, reviews, opinions or preferences are invalid issues.\n",
    "- Lexicographic, syntactic, spelling, grammar or any other language mistakes of the feedback's text are invalid issues.\n",
    "- Again, an issue cannot be supposed to be valid if the customer did not explicitly state it.\n",
    "        \"\"\"\n",
    "\n",
    "        class Input(pydantic.BaseModel):\n",
    "            context: str\n",
    "            feedback: str\n",
    "\n",
    "        class Output(pydantic.BaseModel):\n",
    "            class Issue(pydantic.BaseModel):\n",
    "                title: str = pydantic.Field(description=\"4 to 10 words, which cannot contain the words `issue` (or synonyms), `customer` (or synonyms) or the product's name.\", max_length=100)\n",
    "                description: str = pydantic.Field(description=\"Long, complete explanation, but without redundant information, using the feedback's original words. Must focus solely on the issue by depersonalizing the sentences.\")\n",
    "                steps: List[str] = pydantic.Field(description=\"Precise steps, but very concise, if any, to be able to reproduce the issue, else `[]`.\", max_items=5)\n",
    "\n",
    "            issues: List[Issue] = pydantic.Field(description=\"If any, else `[]`.\")\n",
    "\n",
    "        input: Input = dspy.InputField()\n",
    "        output: Output = dspy.OutputField()\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.generate_issues = ChainOfThought(self.GenerateIssues, max_retries=3, explain_errors=False)\n",
    "\n",
    "        self.activate_assertions(handler=dspy.backtrack_handler, max_backtracks=3)\n",
    "\n",
    "    def forward(self, input: Input) -> dspy.Prediction:\n",
    "        issues = self.generate_issues(input=self.GenerateIssues.Input(\n",
    "            context=input.context,\n",
    "            feedback=input.feedback,\n",
    "        )).output.issues\n",
    "\n",
    "        return dspy.Prediction(output=self.Output(\n",
    "            issues=[self.Output.Issue(\n",
    "                title=issue.title,\n",
    "                description=issue.description,\n",
    "                steps=issue.steps,\n",
    "            ) for issue in issues],\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfoInferrer(dspy.Module):\n",
    "    class Input(pydantic.BaseModel):\n",
    "        context: str\n",
    "        feedback: str\n",
    "        issue: str\n",
    "        categories: List[str]\n",
    "\n",
    "    class Output(pydantic.BaseModel):\n",
    "        severity: str\n",
    "        category: str\n",
    "\n",
    "    class InferInfo(dspy.Signature):\n",
    "        \"\"\"\n",
    "Infer the following information from an issue that an LLM extracted from the feedback of a customer.\n",
    "- Discern the severity, valid options (`severities`) are provided.\n",
    "- Discern the category, valid options (`categories`) are provided.\n",
    "        \"\"\"\n",
    "\n",
    "        class Input(pydantic.BaseModel):\n",
    "            context: str\n",
    "            feedback: str\n",
    "            issue: str\n",
    "            severities: List[str]\n",
    "            categories: List[str]\n",
    "\n",
    "        class Output(pydantic.BaseModel):\n",
    "            severity: str = pydantic.Field(description=\"The valid option that best fits.\")\n",
    "            category: str = pydantic.Field(description=f\"The valid option that best fits, if any, else `{UNKNOWN_OPTION}`.\")\n",
    "\n",
    "        input: Input = dspy.InputField()\n",
    "        output: Output = dspy.OutputField()\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.infer_info = ChainOfThought(self.InferInfo, max_retries=3, explain_errors=False)\n",
    "\n",
    "        self.activate_assertions(handler=dspy.backtrack_handler, max_backtracks=3)\n",
    "\n",
    "    def forward(self, input: Input) -> dspy.Prediction:\n",
    "        info = self.infer_info(input=self.InferInfo.Input(\n",
    "            context=input.context,\n",
    "            feedback=input.feedback,\n",
    "            issue=input.issue,\n",
    "            severities=[severity.replace(\"_\", \" \") for severity in Severity.list()],\n",
    "            categories=list({category.replace(\"_\", \" \") for category in input.categories + [UNKNOWN_OPTION]}),\n",
    "        )).output\n",
    "\n",
    "        severity = info.severity.upper().replace(\" \", \"_\")\n",
    "\n",
    "        dspy.Assert(\n",
    "            severity in Severity.list(),\n",
    "            f'Severity must be {self.InferInfo.Output.model_fields[\"severity\"].description}! `{severity}` is NOT a valid option. Valid options are:\\n' + \"\".join([f\"- {option}\\n\" for option in Severity.list()])\n",
    "        )\n",
    "\n",
    "        category = info.category.upper().replace(\" \", \"_\")\n",
    "        if not input.categories:\n",
    "            category = UNKNOWN_OPTION\n",
    "\n",
    "        dspy.Suggest(\n",
    "            category in input.categories or category == UNKNOWN_OPTION,\n",
    "            f'Category must be {self.InferInfo.Output.model_fields[\"category\"].description}! `{category}` is NOT a valid option. Valid options are:\\n' + \"\".join([f\"- {option}\\n\" for option in input.categories])\n",
    "        )\n",
    "\n",
    "        if category not in input.categories:\n",
    "            category = UNKNOWN_OPTION\n",
    "\n",
    "        return dspy.Prediction(output=self.Output(\n",
    "            severity=severity,\n",
    "            category=category,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IssueExtractor(dspy.Module):\n",
    "    class Input(pydantic.BaseModel):\n",
    "        context: str\n",
    "        categories: List[str]\n",
    "        feedback: str\n",
    "\n",
    "    class Output(pydantic.BaseModel):\n",
    "        class Issue(pydantic.BaseModel):\n",
    "            title: str\n",
    "            description: str\n",
    "            steps: List[str]\n",
    "            severity: str\n",
    "            category: str\n",
    "\n",
    "        issues: List[Issue]\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.IssueGenerator = IssueGenerator\n",
    "        self.generate_issues = self.IssueGenerator()\n",
    "        self.generate_issues.load(\"artifacts/issue_extractor/issue_generator/labeled_few_shot.json\")\n",
    "        self.InfoInferrer = InfoInferrer\n",
    "        self.infer_info = self.InfoInferrer()\n",
    "        self.infer_info.load(\"artifacts/issue_extractor/info_inferrer/labeled_few_shot.json\")\n",
    "\n",
    "    def forward(self, input: Input) -> dspy.Prediction:\n",
    "        generated_issues = self.generate_issues(input=self.IssueGenerator.Input(\n",
    "            context=input.context,\n",
    "            feedback=input.feedback,\n",
    "        )).output.issues\n",
    "\n",
    "        issues = []\n",
    "        for issue in generated_issues:\n",
    "            info = self.infer_info(input=self.InfoInferrer.Input(\n",
    "                context=input.context,\n",
    "                feedback=input.feedback,\n",
    "                issue=issue.description,\n",
    "                categories=input.categories,\n",
    "            )).output\n",
    "\n",
    "            issues.append(self.Output.Issue(\n",
    "                title=issue.title,\n",
    "                description=issue.description,\n",
    "                steps=issue.steps,\n",
    "                severity=info.severity,\n",
    "                category=info.category,\n",
    "            ))\n",
    "\n",
    "        return dspy.Prediction(output=self.Output(\n",
    "            issues=issues,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Issue labels are needed to evaluate the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "m = int(random() * len(feedbacks))\n",
    "fed = feedbacks.iloc[m]\n",
    "\n",
    "print(fed[\"translation\"])\n",
    "print()\n",
    "print(fed[\"categories\"])\n",
    "print(\"=\"*40, m, \"=\"*40)\n",
    "\n",
    "issues = IssueExtractor()(input=IssueExtractor.Input(\n",
    "    context=fed[\"context\"],\n",
    "    categories=fed[\"categories\"],\n",
    "    feedback=fed[\"translation\"],\n",
    ")).output.issues\n",
    "for issue in issues:\n",
    "    print(f\"[{issue.severity}]\", issue.title)\n",
    "    print(\"Category:\", issue.category or \"None\")\n",
    "    print()\n",
    "    print(issue.description)\n",
    "    if issue.steps:\n",
    "        print(\"Steps to reproduce:\")\n",
    "        for i, step in enumerate(issue.steps):\n",
    "            print(f\"{i+1}. {step}\")\n",
    "\n",
    "    print(\"-\"*80)\n",
    "\n",
    "print(\"^\"*40, len(issues),\"^\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuggestionGenerator(dspy.Module):\n",
    "    class Input(pydantic.BaseModel):\n",
    "        context: str\n",
    "        feedback: str\n",
    "\n",
    "    class Output(pydantic.BaseModel):\n",
    "        class Suggestion(pydantic.BaseModel):\n",
    "            title: str\n",
    "            description: str\n",
    "            reason: str\n",
    "\n",
    "        suggestions: List[Suggestion]\n",
    "\n",
    "    class GenerateSuggestions(dspy.Signature):\n",
    "        \"\"\"\n",
    "List valid improvement proposals, feature requests and ideas, that a customer has about a product (context is provided), from the customer's feedback.\n",
    "- Suggestions that the customer did not explicitly state are invalid suggestions.\n",
    "- If the customer is uncertain of a suggestion it is an invalid suggestion.\n",
    "- Suggestions without reasons behind the proposals are still valid suggestions.\n",
    "- Issues, concerns, complaints, reviews, opinions or preferences are invalid suggestions.\n",
    "- Suggestions that come from an issue are invalid suggestions.\n",
    "- Lexicographic, syntactic, spelling, grammar or any other language mistakes of the feedback's text are invalid suggestions.\n",
    "- Again, a suggestion cannot be supposed to be valid if the customer did not explicitly state it.\n",
    "        \"\"\"\n",
    "\n",
    "        class Input(pydantic.BaseModel):\n",
    "            context: str\n",
    "            feedback: str\n",
    "\n",
    "        class Output(pydantic.BaseModel):\n",
    "            class Suggestion(pydantic.BaseModel):\n",
    "                title: str = pydantic.Field(description=\"4 to 10 words, which cannot contain the words `suggestion` (or synonyms), `customer` (or synonyms) or the product's name.\", max_length=100)\n",
    "                description: str = pydantic.Field(description=\"Long, complete explanation, but without redundant information, using the feedback's original words. Must focus solely on the suggestion by depersonalizing the sentences.\")\n",
    "                reason: str = pydantic.Field(description=f'The customer\\'s motivation behind the proposal of the suggestion, if any must always start with `This will`, else `{UNKNOWN_OPTION}`.')\n",
    "\n",
    "            suggestions: List[Suggestion] = pydantic.Field(description=\"If any, else `[]`.\")\n",
    "\n",
    "        input: Input = dspy.InputField()\n",
    "        output: Output = dspy.OutputField()\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.generate_suggestions = ChainOfThought(self.GenerateSuggestions, max_retries=3, explain_errors=False)\n",
    "\n",
    "        self.activate_assertions(handler=dspy.backtrack_handler, max_backtracks=3)\n",
    "\n",
    "    def forward(self, input: Input) -> dspy.Prediction:\n",
    "        suggestions = self.generate_suggestions(input=self.GenerateSuggestions.Input(\n",
    "            context=input.context,\n",
    "            feedback=input.feedback,\n",
    "        )).output.suggestions\n",
    "\n",
    "        return dspy.Prediction(output=self.Output(\n",
    "            suggestions=[self.Output.Suggestion(\n",
    "                title=suggestion.title,\n",
    "                description=suggestion.description,\n",
    "                reason=suggestion.reason if suggestion.reason.upper() != UNKNOWN_OPTION else \"\",\n",
    "            ) for suggestion in suggestions],\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfoInferrer(dspy.Module):\n",
    "    class Input(pydantic.BaseModel):\n",
    "        context: str\n",
    "        feedback: str\n",
    "        suggestion: str\n",
    "        categories: List[str]\n",
    "\n",
    "    class Output(pydantic.BaseModel):\n",
    "        importance: str\n",
    "        category: str\n",
    "\n",
    "    class InferInfo(dspy.Signature):\n",
    "        \"\"\"\n",
    "Infer the following information from a suggestion that an LLM extracted from the feedback of a customer.\n",
    "- Discern the importance, valid options (`importances`) are provided.\n",
    "- Discern the category, valid options (`categories`) are provided.\n",
    "        \"\"\"\n",
    "\n",
    "        class Input(pydantic.BaseModel):\n",
    "            context: str\n",
    "            feedback: str\n",
    "            suggestion: str\n",
    "            importances: List[str]\n",
    "            categories: List[str]\n",
    "\n",
    "        class Output(pydantic.BaseModel):\n",
    "            importance: str = pydantic.Field(description=\"The valid option that best fits.\")\n",
    "            category: str = pydantic.Field(description=f\"The valid option that best fits, if any, else `{UNKNOWN_OPTION}`.\")\n",
    "\n",
    "        input: Input = dspy.InputField()\n",
    "        output: Output = dspy.OutputField()\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.infer_info = ChainOfThought(self.InferInfo, max_retries=3, explain_errors=False)\n",
    "\n",
    "        self.activate_assertions(handler=dspy.backtrack_handler, max_backtracks=3)\n",
    "\n",
    "    def forward(self, input: Input) -> dspy.Prediction:\n",
    "        info = self.infer_info(input=self.InferInfo.Input(\n",
    "            context=input.context,\n",
    "            feedback=input.feedback,\n",
    "            suggestion=input.suggestion,\n",
    "            importances=[importance.replace(\"_\", \" \") for importance in Importance.list()],\n",
    "            categories=list({category.replace(\"_\", \" \") for category in input.categories + [UNKNOWN_OPTION]}),\n",
    "        )).output\n",
    "\n",
    "        importance = info.importance.upper().replace(\" \", \"_\")\n",
    "\n",
    "        dspy.Assert(\n",
    "            importance in Importance.list(),\n",
    "            f'Importance must be {self.InferInfo.Output.model_fields[\"importance\"].description}! `{importance}` is NOT a valid option. Valid options are:\\n' + \"\".join([f\"- {option}\\n\" for option in Importance.list()])\n",
    "        )\n",
    "\n",
    "        category = info.category.upper().replace(\" \", \"_\")\n",
    "        if not input.categories:\n",
    "            category = UNKNOWN_OPTION\n",
    "\n",
    "        dspy.Suggest(\n",
    "            category in input.categories or category == UNKNOWN_OPTION,\n",
    "            f'Category must be {self.InferInfo.Output.model_fields[\"category\"].description}! `{category}` is NOT a valid option. Valid options are:\\n' + \"\".join([f\"- {option}\\n\" for option in input.categories])\n",
    "        )\n",
    "\n",
    "        if category not in input.categories:\n",
    "            category = UNKNOWN_OPTION\n",
    "\n",
    "        return dspy.Prediction(output=self.Output(\n",
    "            importance=importance,\n",
    "            category=category,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuggestionExtractor(dspy.Module):\n",
    "    class Input(pydantic.BaseModel):\n",
    "        context: str\n",
    "        categories: List[str]\n",
    "        feedback: str\n",
    "\n",
    "    class Output(pydantic.BaseModel):\n",
    "        class Suggestion(pydantic.BaseModel):\n",
    "            title: str\n",
    "            description: str\n",
    "            reason: str\n",
    "            importance: str\n",
    "            category: str\n",
    "\n",
    "        suggestions: List[Suggestion]\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.SuggestionGenerator = SuggestionGenerator\n",
    "        self.generate_suggestions = self.SuggestionGenerator()\n",
    "        self.generate_suggestions.load(\"artifacts/suggestion_extractor/suggestion_generator/labeled_few_shot.json\")\n",
    "        self.InfoInferrer = InfoInferrer\n",
    "        self.infer_info = self.InfoInferrer()\n",
    "        self.infer_info.load(\"artifacts/suggestion_extractor/info_inferrer/labeled_few_shot.json\")\n",
    "\n",
    "    def forward(self, input: Input) -> dspy.Prediction:\n",
    "        generated_suggestions = self.generate_suggestions(input=self.SuggestionGenerator.Input(\n",
    "            context=input.context,\n",
    "            feedback=input.feedback,\n",
    "        )).output.suggestions\n",
    "\n",
    "        suggestions = []\n",
    "        for suggestion in generated_suggestions:\n",
    "            info = self.infer_info(input=self.InfoInferrer.Input(\n",
    "                context=input.context,\n",
    "                feedback=input.feedback,\n",
    "                suggestion=suggestion.description,\n",
    "                categories=input.categories,\n",
    "            )).output\n",
    "\n",
    "            suggestions.append(self.Output.Suggestion(\n",
    "                title=suggestion.title,\n",
    "                description=suggestion.description,\n",
    "                reason=suggestion.reason,\n",
    "                importance=info.importance,\n",
    "                category=info.category,\n",
    "            ))\n",
    "\n",
    "        return dspy.Prediction(output=self.Output(\n",
    "            suggestions=suggestions,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Suggestion labels are needed to evaluate the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "m = int(random() * len(feedbacks))\n",
    "fed = feedbacks.iloc[m]\n",
    "\n",
    "print(fed[\"translation\"])\n",
    "print()\n",
    "print(fed[\"categories\"])\n",
    "print(\"=\"*40, m, \"=\"*40)\n",
    "\n",
    "suggestions = SuggestionExtractor()(input=SuggestionExtractor.Input(\n",
    "    context=fed[\"context\"],\n",
    "    categories=fed[\"categories\"],\n",
    "    feedback=fed[\"translation\"],\n",
    ")).output.suggestions\n",
    "for suggestion in suggestions:\n",
    "    print(f\"[{suggestion.importance}]\", suggestion.title)\n",
    "    print(\"Category:\", suggestion.category or \"None\")\n",
    "    print()\n",
    "    print(suggestion.description)\n",
    "    if suggestion.reason:\n",
    "        print(\"Reason:\")\n",
    "        print(suggestion.reason)\n",
    "\n",
    "    print(\"-\"*80)\n",
    "\n",
    "print(\"^\"*40, len(suggestions),\"^\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewExtractor(dspy.Module):\n",
    "    class Input(pydantic.BaseModel):\n",
    "        context: str\n",
    "        categories: List[str]\n",
    "        feedback: str\n",
    "\n",
    "    class Output(pydantic.BaseModel):\n",
    "        class Review(pydantic.BaseModel):\n",
    "            content: str\n",
    "            keywords: List[str]\n",
    "            sentiment: str\n",
    "            emotions: List[str]\n",
    "            intention: str\n",
    "            category: str\n",
    "\n",
    "        review: Review\n",
    "\n",
    "    class InferInfo(dspy.Signature):\n",
    "        \"\"\"\n",
    "Infer the following information from the customer's feedback of a product (context is provided).\n",
    "- List the most important keywords, following the following rules:\n",
    "    - Limit each keyword to 3 words maximum.\n",
    "    - Only include keywords the customer explicitly stated.\n",
    "    - Do not include emojis in the keywords.\n",
    "    - Do not include the name of the product in the keywords.\n",
    "- Discern the sentiment, valid options (`sentiments`) are provided.\n",
    "- Discern the emotions, valid options (`emotions`) are provided.\n",
    "- Discern the intention, valid options (`intentions`) are provided, following the following rules:\n",
    "    - To `retain` means to have the intention to buy again, renew and/or recommend the product.\n",
    "    - To `churn` means to have the intention to return, refund, cancel and/or discourage the product. Critical issues also cause customer churn.\n",
    "    - To `recommend` cannot be assumed if the customer did not explicitly state it (except if synonyms were used).\n",
    "    - To `discourage` is very likely if the customer has the intention to churn.\n",
    "- Discern the category, valid options (`categories`) are provided.\n",
    "        \"\"\"\n",
    "\n",
    "        class Input(pydantic.BaseModel):\n",
    "            context: str\n",
    "            feedback: str\n",
    "            sentiments: List[str]\n",
    "            emotions: List[str]\n",
    "            intentions: List[str]\n",
    "            categories: List[str]\n",
    "\n",
    "        class Output(pydantic.BaseModel):\n",
    "            keywords: List[str] = pydantic.Field(description=\"If any, else `[]`.\", max_items=10)\n",
    "            sentiment: str = pydantic.Field(description=\"The valid option that best fits.\")\n",
    "            emotions: List[str] = pydantic.Field(description=\"The valid options that best fit, if any, else `[]`.\", max_items=4)\n",
    "            intention: str = pydantic.Field(description=f\"The valid option that best fits, if any, else `{UNKNOWN_OPTION}`.\")\n",
    "            category: str = pydantic.Field(description=f\"The valid option that best fits, if any, else `{UNKNOWN_OPTION}`.\")\n",
    "\n",
    "        input: Input = dspy.InputField()\n",
    "        output: Output = dspy.OutputField()\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.infer_info = ChainOfThought(self.InferInfo, max_retries=3, explain_errors=False)\n",
    "\n",
    "        self.activate_assertions(handler=dspy.backtrack_handler, max_backtracks=3)\n",
    "        self.load(\"artifacts/review_extractor/labeled_few_shot.json\")\n",
    "\n",
    "    def forward(self, input: Input) -> dspy.Prediction:\n",
    "        info = self.infer_info(input=self.InferInfo.Input(\n",
    "            context=input.context,\n",
    "            feedback=input.feedback,\n",
    "            sentiments=[sentiment.replace(\"_\", \" \") for sentiment in Sentiment.list()],\n",
    "            emotions=[emotion.replace(\"_\", \" \") for emotion in Emotion.list()],\n",
    "            intentions=[intention.replace(\"_\", \" \") for intention in Intention.list() + [UNKNOWN_OPTION]],\n",
    "            categories=list({category.replace(\"_\", \" \") for category in input.categories + [UNKNOWN_OPTION]}),\n",
    "        )).output\n",
    "\n",
    "        keywords = [keyword.lower() for keyword in info.keywords if keyword]\n",
    "\n",
    "        inexistent_keywords = list(filter(lambda keyword: keyword not in input.feedback.lower(), keywords))\n",
    "        dspy.Suggest(\n",
    "            not inexistent_keywords,\n",
    "            \"All keywords must be included in the customer's feedback! Keywords not included:\\n\" + \"\".join([f\"- {keyword}\\n\" for keyword in inexistent_keywords]),\n",
    "        )\n",
    "\n",
    "        keywords = list(set(keywords) - set(inexistent_keywords))\n",
    "\n",
    "        long_keywords = list(filter(lambda keyword: len(keyword.split()) > 3, keywords))\n",
    "        dspy.Suggest(\n",
    "            not long_keywords,\n",
    "            \"Each keyword must be 3 words maximum! Keywords too long:\\n\" + \"\".join([f\"- {keyword}\\n\" for keyword in long_keywords]),\n",
    "        )\n",
    "\n",
    "        keywords = list(set(keywords) - set(long_keywords))\n",
    "\n",
    "        emoji_keywords = list(filter(lambda keyword: emoji.emoji_count(keyword) > 0, keywords))\n",
    "        dspy.Suggest(\n",
    "            not emoji_keywords,\n",
    "            \"Keywords cannot include emojis! Keywords with emojis:\\n\" + \"\".join([f\"- {keyword}\\n\" for keyword in emoji_keywords]),\n",
    "        )\n",
    "\n",
    "        keywords = list(set(keywords) - set(emoji_keywords))\n",
    "\n",
    "        sentiment = info.sentiment.upper().replace(\" \", \"_\")\n",
    "\n",
    "        dspy.Assert(\n",
    "            sentiment in Sentiment.list(),\n",
    "            f'Sentiment must be {self.InferInfo.Output.model_fields[\"sentiment\"].description}! `{sentiment}` is NOT a valid option. Valid options are:\\n' + \"\".join([f\"- {option}\\n\" for option in Sentiment.list()])\n",
    "        )\n",
    "\n",
    "        emotions = [emotion.upper().replace(\" \", \"_\") for emotion in info.emotions]\n",
    "\n",
    "        invalid_emotions = list(filter(lambda emotion: emotion not in Emotion.list(), emotions))\n",
    "        dspy.Assert(\n",
    "            not invalid_emotions,\n",
    "            f'Emotions must be {self.InferInfo.Output.model_fields[\"emotions\"].description}! Invalid options:\\n' + \"\".join([f\"- {emotion}\\n\" for emotion in invalid_emotions]) + 'Valid options are:\\n' + \"\".join([f\"- {option}\\n\" for option in Emotion.list()]),\n",
    "        )\n",
    "\n",
    "        emotions = list(set(emotions))\n",
    "\n",
    "        intention = info.intention.upper().replace(\" \", \"_\")\n",
    "\n",
    "        dspy.Suggest(\n",
    "            intention in Intention.list() or intention == UNKNOWN_OPTION,\n",
    "            f'Intention must be {self.InferInfo.Output.model_fields[\"intention\"].description}! `{intention}` is NOT a valid option. Valid options are:\\n' + \"\".join([f\"- {option}\\n\" for option in Intention.list()])\n",
    "        )\n",
    "\n",
    "        if intention not in Intention.list():\n",
    "            intention = UNKNOWN_OPTION\n",
    "\n",
    "        category = info.category.upper().replace(\" \", \"_\")\n",
    "        if not input.categories:\n",
    "            category = UNKNOWN_OPTION\n",
    "\n",
    "        dspy.Suggest(\n",
    "            category in input.categories or category == UNKNOWN_OPTION,\n",
    "            f'Category must be {self.InferInfo.Output.model_fields[\"category\"].description}! `{category}` is NOT a valid option. Valid options are:\\n' + \"\".join([f\"- {option}\\n\" for option in input.categories])\n",
    "        )\n",
    "\n",
    "        if category not in input.categories:\n",
    "            category = UNKNOWN_OPTION\n",
    "\n",
    "        return dspy.Prediction(output=self.Output(\n",
    "            review=self.Output.Review(\n",
    "                content=input.feedback,\n",
    "                keywords=keywords,\n",
    "                sentiment=sentiment,\n",
    "                emotions=emotions,\n",
    "                intention=intention,\n",
    "                category=category,\n",
    "            ),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Review labels are needed to evaluate the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "m = int(random() * len(feedbacks))\n",
    "fed = feedbacks.iloc[m]\n",
    "\n",
    "print(fed[\"translation\"])\n",
    "print()\n",
    "print(fed[\"categories\"])\n",
    "print(\"=\"*40, m, \"=\"*40)\n",
    "\n",
    "review = ReviewExtractor()(input=ReviewExtractor.Input(\n",
    "    context=fed[\"context\"],\n",
    "    categories=fed[\"categories\"],\n",
    "    feedback=fed[\"translation\"],\n",
    ")).output.review\n",
    "print(\"Keywords:\")\n",
    "for keyword in review.keywords:\n",
    "    print(f\"  - {keyword}\")\n",
    "print(f\"Sentiment: {review.sentiment}\")\n",
    "print(f\"Emotions: {', '.join(review.emotions)}\")\n",
    "print(f\"Intention: {review.intention}\")\n",
    "print(f\"Category: {review.category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-Lu3HgufU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
